apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-conf
  labels:
    app: gpu-proxy
data:
  nginx.conf: |
    user  nginx;
    worker_processes  1;

    error_log  /var/log/nginx/error.log warn;
    pid        /var/run/nginx.pid;

    events {
        worker_connections  1024;
    }

    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;

        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /var/log/nginx/access.log  main;

        keepalive_timeout  65;

        # --------------------------------------------------------
        # LIMIT CONCURRENCY
        # --------------------------------------------------------
        # Define a limit zone named 'gpu_limit'
        # based on the server_name or a static key to limit GLOBALLY.
        # We use a binary_remote_addr if we wanted per-IP, but we want
        # GLOBAL protection for the single GPU.
        # So we use a constant variable.
        
        limit_conn_zone $binary_remote_addr zone=per_ip:10m;
        
        # We really want a total global limit, not just per IP.
        # Nginx doesn't natively have "global limit" without a trick.
        # The trick: map a constant string to a variable and limit on that.
        map $http_host $global_limit_key {
            default "global_gpu_lock";
        }
        limit_conn_zone $global_limit_key zone=global_gpu:10m;

        upstream ai_backend {
            # Kubernetes balances this across ai-service pods
            server ai-service:8000;
            
            # Keepalive connections to backend significantly improve perf
            keepalive 16;
        }

        server {
            listen 80;
            server_name localhost;

            location / {
                # Concurrency limit: Increased for CPU-based scaling
                limit_conn global_gpu 20;
                
                # Return 503 if busy
                limit_conn_status 503;

                proxy_pass http://ai_backend;
                proxy_http_version 1.1;
                proxy_set_header Connection "";
                proxy_set_header Host $host;
                
                # Timeouts - GPU inference can be slow
                proxy_read_timeout 300s;
                proxy_connect_timeout 300s;
            }
            
            location /nginx_status {
                stub_status;
            }
        }
    }
